{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27380cef",
   "metadata": {},
   "source": [
    "# Week 1: NYC Taxi Ride Duration Prediction – Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f59dcc",
   "metadata": {},
   "source": [
    "In this notebook, I will build a baseline machine learning model to predict the duration of NYC green taxi rides using trip data from January and February 2021 based on Week 1's [MLOps Zoomcamp](https://github.com/DataTalksClub/mlops-zoomcamp) lessons.\n",
    "\n",
    "The data can be found at: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "\n",
    "### Objectives:\n",
    "- Load and explore the NYC Green Taxi trip dataset.\n",
    "- Perform data cleaning and filtering (e.g., removing very short or long rides).\n",
    "- Engineer useful features such as ride distance and pickup/drop-off combinations.\n",
    "- Encode categorical variables using `DictVectorizer`.\n",
    "- Train and evaluate linear regression models (Linear, Lasso, Ridge).\n",
    "- Establish a baseline RMSE score using a hold-out validation set.\n",
    "- Save the model and preprocessing pipeline for later use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa092ddf",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1dd6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow # read parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "daba22c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d8396b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63f934af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d64260",
   "metadata": {},
   "source": [
    "## Data Ingestion & Basic Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286fd5c",
   "metadata": {},
   "source": [
    "read_dataframe(url) downloads a Parquet file directly from the cloud and prepares it for modeling:\n",
    "\n",
    "- Loads the file via pd.read_parquet (pyarrow engine).\n",
    "\n",
    "- Calculates trip duration in minutes from the pickup/drop-off timestamps.\n",
    "\n",
    "- Filters out trips shorter than 1 minute or longer than 60 minutes to remove obvious outliers.\n",
    "\n",
    "- Casts the pickup and drop-off location IDs to strings so they can be one-hot encoded later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb6620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load NYC Green Taxi data from a Parquet URL and apply minimal filtering.\n",
    "    Returns a DataFrame with an extra 'PU_DO' categorical column.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(url, engine=\"pyarrow\")\n",
    "\n",
    "    # trip duration (minutes)\n",
    "    df[\"duration\"] = (\n",
    "        df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    ).dt.total_seconds() / 60\n",
    "\n",
    "    # keep 1–60 min trips\n",
    "    df = df.query(\"1 <= duration <= 60\").copy()\n",
    "\n",
    "    # categorical ids → string then combined route id\n",
    "    df[\"PULocationID\"] = df[\"PULocationID\"].astype(str)\n",
    "    df[\"DOLocationID\"] = df[\"DOLocationID\"].astype(str)\n",
    "    df[\"PU_DO\"] = df[\"PULocationID\"] + \"_\" + df[\"DOLocationID\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d853532",
   "metadata": {},
   "source": [
    "## Feature Engineering with DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5896547",
   "metadata": {},
   "source": [
    "make_X_y(df, dv=None, fit=True) turns the cleaned DataFrame into:\n",
    "\n",
    "- X – sparse one-hot matrix (DictVectorizer).\n",
    "\n",
    "- y – duration vector.\n",
    "\n",
    "- dv – the fitted vectorizer (returned so you can reuse it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30ad78ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def make_X_y(\n",
    "    df: pd.DataFrame,\n",
    "    dv: Optional[DictVectorizer] = None,\n",
    "    fit: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Turn the DataFrame into X (sparse) and y.\n",
    "    Features: one-hot 'PU_DO'  + numeric 'trip_distance'.\n",
    "    \"\"\"\n",
    "    cat = [\"PU_DO\"]\n",
    "    num = [\"trip_distance\"]\n",
    "\n",
    "    records = df[cat + num].to_dict(orient=\"records\")\n",
    "\n",
    "    if dv is None:\n",
    "        dv = DictVectorizer(sparse=True)\n",
    "\n",
    "    X = dv.fit_transform(records) if fit else dv.transform(records)\n",
    "    y = df[\"duration\"].values\n",
    "    return X, y, dv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a95ae",
   "metadata": {},
   "source": [
    "## Train / Validation Split (Jan + Feb 2021 Green Taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c94ca",
   "metadata": {},
   "source": [
    "Train on January 2021 and validate on February 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71b7c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_TRAIN = \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet\"\n",
    "URL_VAL   = \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet\"\n",
    "\n",
    "df_train = read_dataframe(URL_TRAIN)\n",
    "df_val   = read_dataframe(URL_VAL)\n",
    "\n",
    "X_train, y_train, dv = make_X_y(df_train, fit=True)\n",
    "X_val,   y_val,  _   = make_X_y(df_val,   dv=dv, fit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2973d780",
   "metadata": {},
   "source": [
    "## Baseline Model: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b08ba0",
   "metadata": {},
   "source": [
    "Fit an ordinary least-squares model and report RMSE on February 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58151035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 7.479586896300 minutes\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lin_reg.predict(X_val)\n",
    "rmse_lr   = mean_squared_error(y_val, y_pred_lr, squared=False)\n",
    "print(f\"Linear Regression RMSE: {rmse_lr:.12f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad796c4",
   "metadata": {},
   "source": [
    "## Regularised Model: Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c69936",
   "metadata": {},
   "source": [
    "Fit a Lasso model with regularisation (alpha=0.001) and compare its RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "029b3659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression RMSE: 9.233436225721 minutes\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.001)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lasso = lasso.predict(X_val)\n",
    "rmse_lasso   = mean_squared_error(y_val, y_pred_lasso, squared=False)\n",
    "print(f\"Lasso Regression RMSE: {rmse_lasso:.12f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57c449",
   "metadata": {},
   "source": [
    "## Regularised Model: Ridge Regression (alpha = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f60c3",
   "metadata": {},
   "source": [
    "Fit a Ridge model with ℓ² regularisation (alpha=1.0) and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49bd8c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression RMSE: 11.342603943250 minutes\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_val)\n",
    "rmse_ridge   = mean_squared_error(y_val, y_pred_ridge, squared=False)\n",
    "print(f\"Ridge Regression RMSE: {rmse_ridge:.12f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8858ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
